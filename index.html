<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Screen Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-900 text-white p-8">
    <div class="max-w-3xl mx-auto">
        <h1 class="text-3xl font-bold mb-4">AI Screen Assistant</h1>
        
        <div class="mb-6 p-4 bg-gray-800 rounded">
            <label class="block mb-2">Enter Gemini API Key:</label>
            <input type="password" id="apiKey" class="w-full p-2 bg-gray-700 rounded border border-gray-600" placeholder="paste key here...">
            <p class="text-xs text-gray-400 mt-2 italic">*Stored only in your browser session.</p>
        </div>

        <div class="flex gap-4 mb-6">
            <button id="startBtn" class="bg-blue-600 px-4 py-2 rounded hover:bg-blue-500">1. Select Screen</button>
            <button id="analyzeBtn" class="bg-green-600 px-4 py-2 rounded hover:bg-green-500 hidden">2. Ask AI for Help</button>
        </div>

        <div class="grid grid-cols-1 gap-6">
            <video id="preview" autoplay muted class="w-full rounded border-2 border-gray-700 hidden"></video>
            <canvas id="snapshot" class="hidden"></canvas>
            
            <div id="response" class="p-4 bg-gray-800 rounded min-h-[100px] border-l-4 border-blue-500">
                AI feedback will appear here...
            </div>
        </div>
    </div>

    <script>
        let stream = null;
        const video = document.getElementById('preview');
        const canvas = document.getElementById('snapshot');
        const responseDiv = document.getElementById('response');

        // Start Screen Capture
        document.getElementById('startBtn').onclick = async () => {
            try {
                stream = await navigator.mediaDevices.getDisplayMedia({ video: true });
                video.srcObject = stream;
                video.classList.remove('hidden');
                document.getElementById('analyzeBtn').classList.remove('hidden');
            } catch (err) {
                alert("Error: " + err.message);
            }
        };

        // Capture Frame and Send to AI
        document.getElementById('analyzeBtn').onclick = async () => {
            const apiKey = document.getElementById('apiKey').value;
            if (!apiKey) return alert("Please enter an API Key first!");

            responseDiv.innerText = "Analyzing your screen...";

            // Draw current video frame to canvas
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            // Convert to Base64
            const base64Image = canvas.toDataURL('image/jpeg').split(',')[1];

            // Call Gemini API
            try {
                const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{
                            parts: [
                                { text: "Look at this screenshot of my current screen. Explain what is happening and suggest exactly what I should do next to be productive." },
                                { inline_data: { mime_type: "image/jpeg", data: base64Image } }
                            ]
                        }]
                    })
                });
                const data = await res.json();
                responseDiv.innerText = data.candidates[0].content.parts[0].text;
            } catch (err) {
                responseDiv.innerText = "Error calling AI: " + err.message;
            }
        };
    </script>
</body>
</html>
